# -*- coding: utf-8 -*-
"""FINAL_ML_PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GOaudP09t_cffbjKQILa7uNB6NPnX-Pc

# **fraudulent transactions classification**


**Context**

Develop a model for predicting fraudulent transactions for a financial company.

***Data Dictionary:***

**step** - maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation).

**type** - CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.

**amount** - amount of the transaction in local currency.

**nameOrig** - customer who started the transaction

**oldbalanceOrg** - initial balance before the transaction

**newbalanceOrig** - new balance after the transaction

**nameDest** - customer who is the recipient of the transaction

**oldbalanceDest** - initial balance recipient before the transaction. Note that there is not information for customers that start with M (Merchants).

**newbalanceDest** - new balance recipient after the transaction. Note that there is not information for customers that start with M (Merchants).

**isFraud** - This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system.

**isFlaggedFraud** - The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction.

# libraries imports
"""

import seaborn as sns
import zipfile
import os
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import VarianceThreshold
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier

"""# download the dataset"""

zip_file_path='/content/archive (4).zip'

with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
        zip_ref.extractall("/content/fraudulent_transactions")

extracted_files_path = '/content/fraudulent_transactions'

df = pd.read_csv(os.path.join(extracted_files_path, 'Fraud.csv'))

"""downloaded the data into a dataframe

# exploring the dataset

**exploring the dataset is a good practice to understand the datatset and it leads to better preproccessing.**
"""

df.head()

"""checked the head of data to view the first 5 rows"""

size = df.shape
print(f"Number of rows: {size[0]}")
print(f"Number of columns: {size[1]}")

"""checked the size of the data"""

df.dtypes

"""checked data type for each column to make sure that it the data types are correct."""

df.isnull().sum()

"""made sure there is no null values to handle"""

df.duplicated().sum()

"""checked if there is any duplicated values to remove"""

fraud = df[df['isFraud'] == 1]

"""created a datafream that only contains the fraudlant transactions for further exploring."""

sns.histplot(fraud['amount']);
plt.title('Distribution of Fraudulent Transaction Amounts')
plt.show()

"""A histogram that represents the amount for fraudlant transactions we can see that most fradulant transactions were low in amount."""

df['isFraud'].value_counts()

"""there is unbalance in the classes which is normal in our case that most transactions are NOT fraud."""

df[df['isFlaggedFraud']==1]

"""the company has a detection system which is the isFlagged attirbute we filtered to see if the detection system actually detects fraud transactions correctly which is true."""

unique_types = fraud['type'].unique()
print("['type']:", unique_types)

"""we can see that fradulant transactions are either transfer or cash_out."""

plt.pie(x = fraud['type'].value_counts(),autopct='%.3f'
       ,labels=['CASH_OUT','TRANSFER'])
plt.show()

"""a pie chart that shows the type of the transactions which is almost splitted between "TRANSFER" and "CASH_OUT"so if  one of these two types for the transaction is chosen  there is a chance that it is fraud

"""

plt.figure(figsize=(10, 8))
sns.heatmap(df[['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig','oldbalanceDest',
                'newbalanceDest', 'isFraud','isFlaggedFraud']].corr(),
            annot=True
           )
plt.title('Correlation Heatmap of Transaction Features')
plt.show()

"""there is **multi_collinearity** between the features

'oldbalanceDest'with 'newbalanceDest' which is equal to 0.98
'oldbalanceOrg'with 'newbalanceOrig'which is equal to 1

"""

unique_nameOrig_count = df["nameOrig"].nunique()
print("Number of unique values in nameOrig is:", unique_nameOrig_count)

unique_nameDest_count = df["nameDest"].nunique()
print("Number of unique values in nameDest is:", unique_nameDest_count)

"""the number of unique values are extremly high


---


note:in model training we will try to include and exclude the two columns and we will see their impact on the model , because when we searched about it,it recommended to not drop it right away due to high num of unique values.

# feature encoding

**feature encoding is needed because the model can't understand text.**
"""

catigorical = df[['type', 'nameOrig', 'nameDest']]
print(catigorical)

"""a varible named catigorical which has the catogrical columns."""

le = LabelEncoder()
df['type'] = le.fit_transform(df['type'])
df['type'].head()

"""each number represent a catogory {'CASH_IN': 0, 'CASH_OUT': 1, 'DEBIT': 2, 'PAYMENT': 3, 'TRANSFER': 4}"""

df['nameOrig'] = le.fit_transform(df['nameOrig'])
df['nameDest'] = le.fit_transform(df['nameDest'])

print("nameOrig:")
print(df['nameOrig'].head())
print("\n")
print("nameDest:")
print(df['nameDest'].head())

"""# dimontionality reduction

**dimontionality reduction is done to remove the features that are not revelant to reduce noise.**
"""

df = df.drop(['newbalanceDest', 'newbalanceOrig'], axis=1)

"""on the heatmap we saw that there is **multi_collinearity** between the features

'oldbalanceDest'with 'newbalanceDest' which is equal to 0.98
'oldbalanceOrg'with 'newbalanceOrig'which is equal to 1

 so we decided to drop one of each which of the features **because they have similar info** which we landed on ['newbalanceDest', 'newbalanceOrig'] because they were less correlated with our target varible.
"""

df.head()

"""#handling un-balanced data

**handling un-balanced data is important to prevent the model to favour one class on the other.**
"""

non_fraud_transaction=df[df['isFraud']==0]
fraud_transaction=df[df['isFraud']==1]

"""splitted the data into two dataframes which is one for fraud and another for non-fraud"""

print(non_fraud_transaction.shape)
print(fraud_transaction.shape)

#non_fraud_transaction=non_fraud_transaction.sample(n=8213)
non_fraud_transaction=non_fraud_transaction.sample(n=10000)

"""we choose to first make both of them equal in size ,however we increased the sample number during training which gave us better results."""

print(non_fraud_transaction.shape)
print(fraud_transaction.shape)

"""checking the shapes."""

new_df=pd.concat([non_fraud_transaction,fraud_transaction], axis=0)

"""we combined the two data frames into one so we can pass it in training."""

new_df.shape

"""checking the shape to make sure we are on the right path.

#splitting the data

**data is divided:**

*   as training to train the model on
*   as testing to test the model on
"""

x1 = new_df.drop(['isFraud', 'nameOrig', 'nameDest'], axis=1)
x2 = new_df.drop(['isFraud'], axis=1)
y = new_df['isFraud']

"""declared features and the target


---


**note:**considered x1 and x2 to see the affect on model training to whether to keep or drop 'nameOrig', 'nameDest'
"""

#x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(x1, y, test_size=0.3, random_state=42)
#x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(x2, y, test_size=0.3, random_state=42)
x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(x1, y, test_size=0.2, random_state=42)
x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(x2, y, test_size=0.2, random_state=42)

"""*   splitted the data twice because we are experminting with x1 and x2
*   we tried 20% of the data for testing and 80% for training and 30% of the data for testing and 70% for training, with a fixed random state.

**the 20% for testing and 80% for training gave us better results.**

# scaling

**preformed standard scaling to make sure that all features have the same scale to prevent features with large scale from being favoured by the models**
"""

scaler=StandardScaler()
x_train_1=scaler.fit_transform(x_train_1)
x_test_1=scaler.transform(x_test_1)
x_train_2=scaler.fit_transform(x_train_2)
x_test_2=scaler.transform(x_test_2)

"""# model training and evaluation

# naive bayes
"""

model1 = GaussianNB()
model1.fit(x_train_1,y_train_1)
y_pred1=model1.predict(x_test_1)
accuracy1 = accuracy_score(y_test_1, y_pred1)
print("Accuracy : {:.2f}%".format(accuracy1*100))

model2 = GaussianNB()
model2.fit(x_train_2,y_train_2)
y_pred2=model2.predict(x_test_2)
accuracy2 = accuracy_score(y_test_2, y_pred2)
print("Accuracy : {:.2f}%".format(accuracy2*100))

"""based on the accuracy results we can see that the model isn't fitting the data well and if we compared between the two models we can see that model2 is preforming better but still it is not the best.

# logistic regression
"""

model3=LogisticRegression()
model3.fit(x_train_1,y_train_1)
y_pred3=model3.predict(x_test_1)
accuracy3 = accuracy_score(y_test_1, y_pred3)
print("Accuracy : {:.2f}%".format(accuracy3*100))

model4=LogisticRegression()
model4.fit(x_train_2,y_train_2)
y_pred4=model4.predict(x_test_2)
accuracy4 = accuracy_score(y_test_2, y_pred4)
print("Accuracy : {:.2f}%".format(accuracy4*100))

"""based on the accuracy results we can see that the model is preforming better than naive bayes and if we compared between the two models we can see that model4 is preforming better.

***naive bayes and logistic regression both had better results if we kept the features 'nameOrig' and 'nameDest'***

# random forest
"""

model5=RandomForestClassifier()
model5.fit(x_train_1,y_train_1)
y_pred5=model5.predict(x_test_1)
accuracy5 = accuracy_score(y_test_1, y_pred5)
print("Accuracy : {:.2f}%".format(accuracy5*100))

model6=RandomForestClassifier()
model6.fit(x_train_2,y_train_2)
y_pred6=model6.predict(x_test_2)
accuracy6 = accuracy_score(y_test_2, y_pred6)
print("Accuracy : {:.2f}%".format(accuracy6*100))

"""based on the accuracy score the model is fitting the data well even better than the previous models , however the model preformed better when dropping  'nameOrig', 'nameDest'.

# Interpreting the Results:

1.we used the following models


*   naive bayes
*   logistic regression
*   random forest

**naive bayes** had the worst fit among the others but it preformed better when dropping 'nameOrig', 'nameDest'.

**logistic regression** had the good fit and it similarly to naive bayes  preformed better when dropping 'nameOrig', 'nameDest'.

**random forest** had the best fit among the other models but it differs when it came to dropping the columns 'nameOrig', 'nameDest' , dropping the columns had better effect on it.

*maybe keeping the columns or dropping them effect depends on the type of model*

2.the split 20%-80% had better results

3.increasing the sample of non fraudlent transactions led to better generelisations.

**conclusion:** we will choose for our project model5 as it led to better results.
"""
