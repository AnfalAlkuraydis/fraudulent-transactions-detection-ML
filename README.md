<div align="center">

# ğŸ’³ **Fraudulent Transactions Classification**

![Python](https://img.shields.io/badge/Python-3.9%2B-3776AB?logo=python&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-ML-F7931E?logo=scikitlearn&logoColor=white)
![pandas](https://img.shields.io/badge/pandas-Data-150458?logo=pandas&logoColor=white)
![numpy](https://img.shields.io/badge/numpy-NDArray-013243?logo=numpy&logoColor=white)
![matplotlib](https://img.shields.io/badge/Matplotlib-Vis-11557C)
![seaborn](https://img.shields.io/badge/Seaborn-Vis-4C9A2A)

Baseline machineâ€‘learning pipeline to detect **fraudulent financial transactions** on a Kaggle dataset.

</div>

---

## ğŸ“Œ Project Overview
The dataset simulates **30 days of transactions**, where only a **small fraction are fraud**.  
The goal is to build a **simple, explainable** baseline that:
- explores fraud patterns,
- applies sane preprocessing,
- compares classical models,
- and selects a solid starting point for future work.

---

## ğŸ“‚ Dataset
Kaggle â€” **Fraudulent Transactions Dataset**  
https://www.kaggle.com/datasets/chitwanmanchanda/fraudulent-transactions-data

Main fields include transaction **type**, **amount**, and account **balances** before/after.  
Class labels: `isFraud` and `isFlaggedFraud`.

---

## ğŸ”„ Pipeline

```mermaid
flowchart LR
  A["Dataset<br/>30 days of transactions"] --> B["EDA<br/>distributions Â· fraud rate Â· correlations"]
  B --> C["Preprocessing<br/>encode categoricals Â· drop collinear Â· scale"]
  C --> D["Split<br/>train 80% / test 20%"]
  D --> E["Modeling<br/>Naive Bayes Â· Logistic Â· Random Forest"]
  E --> F["Evaluation<br/>accuracy"]
  F --> G["Model selection<br/>Random Forest"]

```

---

## ğŸ› ï¸ What Was Done

### 1) **Exploratory Data Analysis (EDA)**
- Fraud incidence, value distributions, and transaction **type** mix.
- Visualizations: histograms, pie charts, correlation heatmaps.

### 2) **Preprocessing**
- **Categoricals:** encoded `type`, `nameOrig`, `nameDest` (tested both **with** and **without** the highâ€‘cardinality IDs).
- **Collinearity:** dropped `newbalanceDest`, `newbalanceOrig` when redundant/leaky.
- **Class balance:** downsampled/undersampled for quick baselines (see *Future Improvements*).

### 3) **Modeling**
- Compared **Naive Bayes**, **Logistic Regression**, **Random Forest** (with standard scaling where appropriate).
- 80/20 **trainâ€“test split**; basic hyperparameters.

---

## ğŸ“Š Results (Baseline Summary)
- **Naive Bayes** â€” weak: poor fit to continuous/imbalanced data.  
- **Logistic Regression** â€” decent but underfits nonâ€‘linear patterns.  
- **Random Forest** â€” **best baseline accuracy**, especially when *excluding* `nameOrig`/`nameDest` (high cardinality & potential leakage).  

**Chosen baseline:** **Random Forest** with selected features removed.

---

## ğŸ§­ Reproducibility

### Environment
```bash
git clone https://github.com/AnfalAlkuraydis/fraudulent-transactions-detection-ML.git
cd fraudulent-transactions-detection-ML

# optional: create a virtual env
python -m venv .venv
# Windows:
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

pip install -r requirements.txt  # or: pip install numpy pandas scikit-learn matplotlib seaborn
```

---

## ğŸ”® Future Improvements
1. **Imbalanced Learning:** SMOTE / SMOTEâ€‘Tomek, **class weights**, focal loss (for trees: `class_weight='balanced'`).  
2. **Feature Engineering:** timeâ€‘ofâ€‘day, rolling stats per account, velocity features.  
3. **Modeling:** hyperparameter search; try **XGBoost/LightGBM/CatBoost**.  
4. **Evaluation:** report **PRâ€‘AUC**, calibration curves, and businessâ€‘aligned **cost metrics**.  
5. **Deployment:** pickle the model & build a small **FastAPI** service for realâ€‘time scoring.  
6. **Explainability:** permutation importance, SHAP for top features.

---

<div align="center">
Made with â¤ï¸ â€” a clean baseline thatâ€™s ready to grow into a production fraud detector.
</div>
